# -*- coding: utf-8 -*-
# !/usr/bin/env python3

# Convert Adlam encoded text to Unicode.
from __future__ import absolute_import, division, print_function

import adlamToLatin

import re
import sys

from converterBase import ConverterBase

# from convertDoc2 import ConvertDocx

# Script index
ADLAM2LATIN = 4
LATIN2ADLAM = 3

FONTS_TO_CONVERT = [
  ['Fulfulde - Aissata', 'arab'],
  ['Fulfulde - Fuuta', 'arab'],
  ['Fulfulde - Pulaar', 'arab'],
  ['Times New Roman', 'latn'],
  ['Adlam2Latn', 'adlam2latn']  # Special for Adlam to Latin transliteration
]

thisDefaultOutputFont = 'Noto Sans Adlam'

# Character constants for conversion
adlamNasalizationMark = u'\U0001E94B'
adlamInitialExclamationMark = u'\U0001E95E'
adlamInitialQuestionMark = u'\U0001E95F'
reverseQuestionMark = u'\ue2e2'

class AdlamConverter(ConverterBase):
    private_use_map = {
        'arab': {
            u'\u0628': u'\U0001e900',
            u'\u062a': u'\U0001e901',
            u'\u062b': u'\U0001e902',
            u'\u062c': u'\U0001e903',
            u'\u062d': u'\U0001e904',
            u'\u062e': u'\U0001e905',
            u'\u0633': u'\U0001e906',
            u'\u0634': u'\U0001e907',
            u'\u0635': u'\U0001e908',
            u'\u0636': u'\U0001e909',
            u'\u0637': u'\U0001e90a',
            u'\u0638': u'\U0001e90b',
            u'\u0639': u'\U0001e90c',
            u'\u063a': u'\U0001e90d',
            u'\u0640': u'\U0001e90e',
            u'\u0641': u'\U0001e90e',
            u'\u0642': u'\U0001e90f',
            u'\u0643': u'\U0001e910',
            u'\u0644': u'\U0001e911',
            u'\u0645': u'\U0001e912',
            u'\u0646': u'\U0001e913',
            u'\u064a': u'\U0001e914',
            u'\u067b': u'\U0001e915',
            u'\u067e': u'\U0001e916',
            u'\u0683': u'\U0001e917',
            u'\u0684': u'\U0001e918', # ??
            u'\u0686': u'\U0001e919',
            u'\u0687': u'\U0001e91a',
            u'\u06a8': u'\U0001e91b',
            u'\u06af': u'\U0001e904',

            # Diacritics
            u'\u0640': u'\U0001e946', # ?? Maybe underscore?
            u'\u064b': u'\U0001e94a',
            u'\u064c': u'\U0001e946',
            u'\u064d': u'\U0001e945',
            u'\u064e': u'\U0001e944',
            u'\u064f': u'\u0027', # TBD: maybe Farsi apostrophe joiner
            u'\u0650': u'\U0001e948',
            u'\u0651': u'\U0001e947',
            u'\u0655': u'\U0001e900', # TBD
            u'\u0658': u'\U0001e900', # TBD
            u'\u0659': u'\U0001e944', # TBD
            u'\u065d': u'\U0001e944',
            u'\u065e': u'\U0001e944',
            u'\u06b3': u'\U0001e945',

            # Digits
            u'\u0660': u'\U0001e950',
            u'\u0661': u'\U0001e951',
            u'\u0662': u'\U0001e952',
            u'\u0663': u'\U0001e953',
            u'\u0664': u'\U0001e954',
            u'\u0665': u'\U0001e955',
            u'\u0666': u'\U0001e956',
            u'\u0667': u'\U0001e957',
            u'\u0668': u'\U0001e958',
            u'\u0669': u'\U0001e959',

            # Punctuation & space
            u'\u0601': adlamInitialExclamationMark,  # Initial 
            u'\u060c': u'\u2e41',
            u'\u060b': u'\u204f',
            # u',': u'â¹',
            u' ': u' ',
            ':': ':',
            '!': '!',
            u'ØŒ': u'\u2E41',
            u'Ø›': u'\u204F',
            u'ØŸ': u'\u2E2E',
            # '?': '?',
            ')': ')',
            '(': '(',
            '-': '-',
            '.': '.',
            '/': '/',

            u'\u00c0': u'\u0027', # Simple apostrophe
            u'\u00c3': u'\u2022',
            u'\u00eb': u'\u2022',
            u'\u00ed': u'\u0027',
            u'\u00f8': u'\U0001e9905',
            u'\u00f9': u'\u2022',
            u'\u0153': u'\U0001e9909',
            u'\u0178': u'\U0001e9914',
            u'\u0192': u'\U0001e9900',
            u'\u0301': u'\u0027',
            u'\u03c0': u'\U0001e914',
            u'\u0394': u'\U0001e901',
            u'\u200c': u'',  # Not needed in Adlam
            u'\u200d': u'',  # Not needed in Adlam
            u'\u201c': u'\u201c',
            u'\u201d': u'\u201d',
            u'\u2126': u'\U0001e90b',
            u'\u2211': u'\U0001e909',
            u'\u2248': u'\U0001e90a',
            u'\ufefe': u'\U0001e944',
            u'\u0027': u'\U0001294b',  # adlamNasalizationMark,
        },
        'latn': {
            '[\u2008\u0020]*Â»': 'â€œ\u201d',
            'Â«\u2008': '\u201c',
            'Â«\u0020': '\u201c',
            'Â»': '\u201d',
            'Â«': '\u201câ€',
            ' ': u' ',
            'A': u'ğ¤€',
            'a': u'ğ¤¢',
            'AA': u'ğ¤€ğ¥„',
            'Aa': u'ğ¤€ğ¥„',
            'aa': u'ğ¤¢ğ¥„',
            'B': u'ğ¤„',
            'b': u'ğ¤¦',
            'BB': u'ğ¤„ğ¥†',
            'Bb': u'ğ¤„ğ¥†',
            'bb': u'ğ¤¦ğ¥†',
            'Æ': u'ğ¤‡',
            'É“': u'ğ¤©',
            'ÆÆ': u'ğ¤‡ğ¥†',
            'ÆÉ“': u'ğ¤‡ğ¥†',
            'É“Æ': u'ğ¤©ğ¥†',
            'É“É“': u'ğ¤©ğ¥†',
            'BH': u'ğ¤‡',
            'Bh': u'ğ¤‡',
            'BBH': u'ğ¤‡ğ¥†',
            'Bbh': u'ğ¤‡ğ¥†',
            'bh': u'ğ¤©',
            'bbh': u'ğ¤©ğ¥†',
            'C': u'ğ¤•',
            'c': u'ğ¤·',
            'CC': u'ğ¤•ğ¥†',
            'Cc': u'ğ¤•ğ¥†',
            'cc': u'ğ¤·ğ¥†',
            'D': u'ğ¤',
            'd': u'ğ¤£',
            'DD': u'ğ¤ğ¥†',
            'Dd': u'ğ¤ğ¥†',
            'dd': u'ğ¤£ğ¥†',
            'ÆŠ': u'ğ¤',
            'É—': u'ğ¤¯',
            'ÆŠÆŠ': u'ğ¤ğ¥†',
            'ÆŠÉ—': u'ğ¤ğ¥†',
            'É—É—': u'ğ¤¯ğ¥†',
            'DH': u'ğ¤',
            'Dh': u'ğ¤',
            'dH': u'ğ¤¯',
            'dh': u'ğ¤¯',
            'DDH': u'ğ¤ğ¥†',
            'Ddh': u'ğ¤ğ¥†',
            'ddh': u'ğ¤¯ğ¥†',
            'DY': u'ğ¤”',
            'Dy': u'ğ¤”',
            'dY': u'ğ¤¶',
            'dy': u'ğ¤¶',
            'E': u'ğ¤‰',
            'e': u'ğ¤«',
            'EE': u'ğ¤‰ğ¥…',
            'Ee': u'ğ¤‰ğ¥…',
            'ee': u'ğ¤«ğ¥…',
            'F': u'ğ¤Š',
            'f': u'ğ¤¬',
            'FF': u'ğ¤Šğ¥†',
            'Ff': u'ğ¤Šğ¥†',
            'ff': u'ğ¤¬ğ¥†',
            'G': u'ğ¤˜',
            'g': u'ğ¤º',
            'GG': u'ğ¤˜ğ¥†',
            'Gg': u'ğ¤˜ğ¥†',
            'gg': u'ğ¤ºğ¥†',
            'GB': u'ğ¤',
            'gb': u'ğ¥€',
            'GGB': u'ğ¤ğ¥†',
            'Ggb': u'ğ¤ğ¥†',
            'ggb': u'ğ¥€ğ¥†',
            'H': u'ğ¤–',
            'h': u'ğ¤¸',
            'HH': u'ğ¤–ğ¥†',
            'Hh': u'ğ¤–ğ¥†',
            'hh': u'ğ¤¸ğ¥†',
            'I': u'ğ¤‹',
            'i': u'ğ¤­',
            'II': u'ğ¤‹ğ¥…',
            'Ii': u'ğ¤‹ğ¥…',
            'ii': u'ğ¤­ğ¥…',
            'J': u'ğ¤”',
            'j': u'ğ¤¶',
            'JJ': u'ğ¤”ğ¥†',
            'Jj': u'ğ¤”ğ¥†',
            'jj': u'ğ¤¶ğ¥†',
            'K': u'ğ¤‘',
            'k': u'ğ¤³',
            'KK': u'ğ¤‘ğ¥†',
            'Kk': u'ğ¤‘ğ¥†',
            'kk': u'ğ¤³ğ¥†',
            'KH': u'ğ¤',
            'kh': u'ğ¤¿',
            'KKH': u'ğ¤ğ¥†',
            'Kkh': u'ğ¤ğ¥†',
            'kkh': u'ğ¤¿ğ¥†',
            'X': u'ğ¤',
            'x': u'ğ¤¿',
            'XX': u'ğ¤ğ¥†',
            'Xx': u'ğ¤ğ¥†',
            'xx': u'ğ¤¿ğ¥†',
            'L': u'ğ¤‚',
            'l': u'ğ¤¤',
            'LL': u'ğ¤‚ğ¥†',
            'Ll': u'ğ¤‚ğ¥†',
            'll': u'ğ¤¤ğ¥†',
            'M': u'ğ¤ƒ',
            'm': u'ğ¤¥',
            'MM': u'ğ¤ƒğ¥†',
            'Mm': u'ğ¤ƒğ¥†',
            'mm': u'ğ¤¥ğ¥†',
            'N': u'ğ¤',
            'n': u'ğ¤²',
            'NN': u'ğ¤ğ¥†',
            'Nn': u'ğ¤ğ¥†',
            'nn': u'ğ¤²ğ¥†',
            'ÅŠ': u'ğ¤›',
            'Å‹': u'ğ¤½',
            'ÅŠÅŠ': u'ğ¤›ğ¥†',
            'ÅŠÅ‹': u'ğ¤›ğ¥†',
            'Å‹Å‹': u'ğ¤½ğ¥†',
            'NH': u'ğ¤›',
            'Nh': u'ğ¤›',
            'nH': u'ğ¤½',
            'nh': u'ğ¤½',
            'NNH': u'ğ¤›ğ¥†',
            'Nnh': u'ğ¤›ğ¥†',
            'nnh': u'ğ¤½ğ¥†',
            'Ã‘': u'ğ¤™',
            'Ã±': u'ğ¤»',
            'Ã‘Ã‘': u'ğ¤™ğ¥†',
            'Ã‘Ã±': u'ğ¤™ğ¥†',
            'Ã±Ã±': u'ğ¤»ğ¥†',
            'NY': u'ğ¤™',
            'ny': u'ğ¤»',
            'NNY': u'ğ¤™ğ¥†',
            'Nny': u'ğ¤™ğ¥†',
            'nny': u'ğ¤»ğ¥†',
            'O': u'ğ¤Œ',
            'o': u'ğ¤®',
            'OO': u'ğ¤Œğ¥…',
            'Oo': u'ğ¤Œğ¥…',
            'oo': u'ğ¤®ğ¥…',
            'P': u'ğ¤†',
            'p': u'ğ¤¨',
            'PP': u'ğ¤†ğ¥†',
            'Pp': u'ğ¤†ğ¥†',
            'pp': u'ğ¤¨ğ¥†',
            'KP': u'ğ¤ ',
            'kp': u'ğ¥‚',
            'KKP': u'ğ¤ ğ¥†',
            'Kkp': u'ğ¤ ğ¥†',
            'kkp': u'ğ¥‚ğ¥†',
            'Q': u'ğ¤—',
            'q': u'ğ¤¹',
            'QQ': u'ğ¤—ğ¥†',
            'Qq': u'ğ¤—ğ¥†',
            'qq': u'ğ¤¹ğ¥†',
            'GH': u'ğ¤—',
            'gh': u'ğ¤¹',
            'GGH': u'ğ¤—ğ¥†',
            'Ggh': u'ğ¤—ğ¥†',
            'ggh': u'ğ¤¹ğ¥†',
            'R': u'ğ¤ˆ',
            'r': u'ğ¤ª',
            'RR': u'ğ¤ˆğ¥†',
            'Rr': u'ğ¤ˆğ¥†',
            'rr': u'ğ¤ªğ¥†',
            'S': u'ğ¤…',
            's': u'ğ¤§',
            'SS': u'ğ¤…ğ¥†',
            'Ss': u'ğ¤…ğ¥†',
            'ss': u'ğ¤§ğ¥†',
            'SH': u'ğ¤¡',
            'Sh': u'ğ¤¡',
            'sh': u'ğ¥ƒ',
            'sH': u'ğ¥ƒ',
            'SSH': u'ğ¤¡ğ¥†',
            'Ssh': u'ğ¤¡ğ¥†',
            'ssh': u'ğ¥ƒğ¥†',
            'T': u'ğ¤š',
            't': u'ğ¤¼',
            'TT': u'ğ¤šğ¥†',
            'Tt': u'ğ¤šğ¥†',
            'tt': u'ğ¤¼ğ¥†',
            'TY': u'ğ¤•',
            'Ty': u'ğ¤•',
            'tY': u'ğ¤·',
            'tY': u'ğ¤·',
            'U': u'ğ¤“',
            'u': u'ğ¤µ',
            'UU': u'ğ¤“ğ¥…',
            'Uu': u'ğ¤“ğ¥…',
            'uu': u'ğ¤µğ¥…',
            'V': u'ğ¤œ',
            'v': u'ğ¤¾',
            'VV': u'ğ¤œğ¥†',
            'Vv': u'ğ¤œğ¥†',
            'vv': u'ğ¤¾ğ¥†',
            'W': u'ğ¤',
            'w': u'ğ¤±',
            'WW': u'ğ¤ğ¥†',
            'Ww': u'ğ¤ğ¥†',
            'ww': u'ğ¤±ğ¥†',
            'Y': u'ğ¤’',
            'y': u'ğ¤´',
            'YY': u'ğ¤’ğ¥†',
            'Yy': u'ğ¤’ğ¥†',
            'yy': u'ğ¤´ğ¥†',
            'Æ³': u'ğ¤',
            'Æ´': u'ğ¤°',
            'Æ³Æ³': u'ğ¤ğ¥†',
            'Æ³Æ´': u'ğ¤ğ¥†',
            'Æ´Æ´': u'ğ¤°ğ¥†',
            'YH': u'ğ¤',
            'yh': u'ğ¤°',
            'YYH': u'ğ¤ğ¥†',
            'Yyh': u'ğ¤ğ¥†',
            'yyh': u'ğ¤°ğ¥†',
            'Z': u'ğ¤Ÿ',
            'z': u'ğ¥',
            'ZZ': u'ğ¤Ÿğ¥†',
            'Zz': u'ğ¤Ÿğ¥†',
            'zz': u'ğ¥ğ¥†',
            'ND': "ğ¤'ğ¤",
            'Nd': "ğ¤'ğ¤",
            'nd': "ğ¤²'ğ¤£",
            'MB': "ğ¤'ğ¤„",
            'Mb': "ğ¤'ğ¤„",
            'mb': "ğ¤²'ğ¤¦",
            'NJ': "ğ¤'ğ¤”",
            'Nj': "ğ¤'ğ¤”",
            'nj': "ğ¤²'ğ¤¶",
            'NG': "ğ¤'ğ¤˜",
            'Ng': "ğ¤'ğ¤˜",
            'ng': "ğ¤²'ğ¤º",
            'nnd': u'ğ¤²ğ¤£',
            'mmb': u'ğ¤¥ğ¤¦',
            'nnj': u'ğ¤²ğ¤¶',
            'nng': u'ğ¤²ğ¤º',
            '0': u'ğ¥',
            '1': u'ğ¥‘',
            '2': u'ğ¥’',
            '3': u'ğ¥“',
            '4': u'ğ¥”',
            '5': u'ğ¥•',
            '6': u'ğ¥–',
            '7': u'ğ¥—',
            '8': u'ğ¥˜',
            '9': u'ğ¥™',
            '.': u'.',
            ',': u'â¹',
            '\u061f': reverseQuestionMark,
            ':': ':',
            '!': '!',
            "\u0027": adlamNasalizationMark,
        },
    }
    # For splitting
    latn_regex = re.compile(
        r'(BBH|Bbh|bbh|DDH|Ddh|ddh|GGB|Ggb|ggb|KKH|Kkh|kkh|NNH|Nnh|nnh|NNY|Nny|nny|KKP|Kkp|kkp|GGH|Ggh|ggh|SSH|Ssh|ssh|YYH|Yyh|yyh|nnd|mmb|nnj|nng|AA|Aa|aa|BB|Bb|bb|ÆÆ|ÆÉ“|É“Æ|É“É“|BH|Bh|bh|CC|Cc|cc|DD|Dd|dd|ÆŠÆŠ|ÆŠÉ—|É—É—|DH|Dh|dH|dh|DY|Dy|dY|dy|EE|Ee|ee|FF|Ff|ff|GG|Gg|gg|GB|gb|HH|Hh|hh|II|Ii|ii|JJ|Jj|jj|KK|Kk|kk|KH|kh|XX|Xx|xx|LL|Ll|ll|MM|Mm|mm|NN|Nn|nn|ÅŠÅŠ|ÅŠÅ‹|Å‹Å‹|NH|Nh|nH|nh|Ã‘Ã‘|Ã‘Ã±|Ã±Ã±|NY|ny|OO|Oo|oo|PP|Pp|pp|KP|kp|QQ|Qq|qq|GH|gh|RR|Rr|rr|SS|Ss|ss|SH|Sh|sh|sH|TT|Tt|tt|TY|Ty|tY|ty|UU|Uu|uu|VV|Vv|vv|WW|Ww|ww|YY|Yy|yy|Æ³Æ³|Æ³Æ´|Æ´Æ´|YH|yh|ZZ|Zz|zz|ND|Nd|nd|MB|Mb|mb|NJ|Nj|nj|NG|Ng|ng|[a-zÃ±É“]|[A-ZÆÃ‘]|[0-9]|Â«[\u2008\u0020]?|[\u2008\u0020]?Â»|\.|\u0020)')


    def __init__(self, oldFontList=FONTS_TO_CONVERT, newFont=None,
                 defaultOutputFont=thisDefaultOutputFont):

        self.encodingScripts = []  # If given, tells the Script of incoming characters
        self.oldFonts = []

        for item in oldFontList:
            if isinstance(item, list):
                self.oldFonts.append(item[0])
                self.encodingScripts.append(item[1])
            else:
                self.oldFonts.append(item)

        # Default script = 'arab'
        self.scriptToConvert = 'arab'
        self.scriptIndex = 0

        if newFont:
            self.unicodeFont = newFont
        else:
            self.unicodeFont = defaultOutputFont
        self.setScriptRange(0x1e900, 0x1e95f)
        self.setUpperCaseRange(0x1e900, 0x1e921)
        self.setLowerCaseRange(0x1e922, 0x1e943)
        self.description = 'Converts Adlam font encoding to Unicode'

        self.defaultOutputFont = "Noto Sans Adlam New"


        self.forceFont = True  # May be used to set all font fields to the Unicode font

        self.isRtl = True

        self.description = 'Converts Adlam font encoding to Unicode'
        self.ignore_start_of_sentence = re.compile(
            r'([\U0001E950-\U0001E959\u0020\(\)\- \.]+)')

        self.encoding = None
        self.debug = False

        self.setLowerMode(False)
        self.setSentenceMode(False)

        self.end_of_sentence_pattern = re.compile(r'([\.\?\!\â¸®\ØŸ$])')

        # For inserting question and exclamation before sentences.
        self.pre_punctuation = {
            '?': adlamInitialQuestionMark,
            'ØŸ': adlamInitialQuestionMark,
            'â¸®': adlamInitialQuestionMark,
            '!': adlamInitialExclamationMark,
            '\u061f': adlamInitialQuestionMark,
        }

        # How words are split in Adlam text - split on non-Adlam text
        self.wordSplitRegEx = re.compile(r'\W')

        self.collectConvertedWordFrequency = True
        self.convertedWordFrequency = {}

        # Information on language detection
        self.detectLang = False
        self.ignoreLangs = []  # Language codes for not conversion

    # TODO: check input and conversion tables for Unicode NFC normalization.
  
    
    def setScriptIndex(self, newIndex=0):
        # 0 = 'arab', 1 = 'latn'
        # ?? Adlam to Latin?
        self.scriptIndex = newIndex
        self.scriptToConvert = self.encodingScripts[self.scriptIndex]

    # Split input into tokens for script conversion
    def tokenizeText(self, textIn):
        if self.scriptIndex == 0:
            # Split into Arabic characters
            return [textIn]
        elif self.scriptIndex == 3:
            # Latin - break into tokens using a regular expression
            # Remove empty strings
            return [i for i in self.token_splitter.split(textIn) if i]
        elif self.scriptIndex == 4:
            # Adlam to Latin
            return [i for i in self.token_splitter.split(textIn) if i]

    # Consider the font information if relevant, e.g., underlining.
    # fontTextInfo: a list of font data for this code, including
    # formatting for each piece.
    def convertText(self, textIn, fontTextInfo=None, fontIndex=0):
        if self.debug:
            print('convertText index= %s, text = %s' % (fontIndex, textIn))

        self.encoding = self.encodingScripts[fontIndex]
        if fontIndex < 4:
            encoding_map = self.private_use_map[self.encoding]
            self.token_splitter = self.latn_regex
        else:
            # Conversion from Adlam to Latin
            convertData = adlamToLatin.adlamToLatinConvert()
            encoding_map = convertData.adlam_to_latin_map
            self.token_splitter = convertData.adlam_split_regex

        self.scriptIndex = fontIndex
        if not fontTextInfo:
            # Only raw text, without formatting or structure information.

            if self.debug:
                print('****** TEXT = %s' % textIn)
            result = self.convertString(textIn, None, encoding_map)
            if self.debug:
                print('   convertText result= %s' % (result))
            return result

        # Take the data from the fontTextInfo field.
        convertList = []
        for item in fontTextInfo:
            tags = []
            for fmt in item[1]:
                loc = fmt.tag.find('}')
                tags.append(fmt.tag[loc + 1:])

            convertList.append(
                self.convertString(item[0], tags, encoding_map))
        if self.debug:
            print('  --> out  = %s' % ''.join(convertList))

        return ''.join(convertList)

    # Handles details of converting the text, including case conversion.
    def convertString(self, textIn, fontInfo,
                      conversion_map):
        # type: (object, object, object) -> object
        convertedList = []
        convertResult = ''

        tokens = self.tokenizeText(textIn)
        if not tokens:
            return convertResult

        if self.debug:
            print('------- Tokens %s' % tokens)
        
        if self.debug:
          print('$$$$$ text = %s, fontInfo = %s' %
                (textIn, fontInfo))  #fontInfo))
        for c in tokens:
          # Special handling if needed
          out = c
          if c in conversion_map:
            out = conversion_map[c]
          else:
            if self.debug:
              print('----- input %s not found' %
                    (c))

          # Special case for handling underlined text
          convertedList.append(out)

        convertResult = ''.join(convertedList)

        if self.lower_mode:
          convertResult = self.toLower(convertResult)

        return convertResult

    def computeSentenceStartsEnds(self, text):
         # Get all the positions of sentence endings
         all_sentence_ends = self.end_of_sentence_pattern.finditer(text)
         text_len = len(text)
         if not all_sentence_ends:
             # No sentence endings. Should first be capitalized?
             return None
         sentence_starts = [0]
         ignore_match = self.ignore_start_of_sentence.match(text)
         if ignore_match:
             sentence_starts[0] = ignore_match.end()
         sentence_ends = []
         for sentence_end in all_sentence_ends:
             # Position and character of this sentence ending
             sentence_ends.append((sentence_end.start(), sentence_end.group(0)[0]))
             end_pos = sentence_end.end()
             while end_pos < text_len and (
                 text[end_pos] == ' ' or text[end_pos] == '\r'
                 or text[end_pos] == '\t' or text[end_pos] == '\n'):
                 end_pos += 1
             # Move the letter content
             #         self.ignore_start_of_sentence = re.compile(
             # r'([\U0001E950\U0001E959\u0020()]+)')
             start_pos = end_pos
             if start_pos < text_len:
                 ignore_match = self.ignore_start_of_sentence.match(text[start_pos:])
                 if ignore_match:
                     start_pos += ignore_match.end() - 1
             sentence_starts.append(start_pos)
         # The paragraph text ends a sentence
         sentence_ends.append((len(text)-1, '$'))
         return sentence_ends, sentence_starts

    def mapRunsToParagraphTextPosisions(self, runs):
        # Mapping of run starts & ends to text positions
        run_map = []
        pos = 0
        run_index = 0
        for run in runs:
            if run.text:
                run_length = len(run.text)
                run_map.append((pos, pos + len(run.text) - 1, run, run_index))
                pos += len(run.text)
            run_index += 1
        return run_map

    def processParagraphRuns(self, p):
        # Handle the text within each paragraph
        if not p.text:
            # Nothing to process
            return

        # Check on the language of the paragraph. May don't convert.
        if self.detectLang:
            detected = self.detectLang.classify(p.text.strip())
            # print('%s in %s' % (detected, p.text))
            if detected[0] in self.ignoreLangs:
                return
            
        for run in p.runs:
            run.text = self.convertText(run.text, None, self.scriptIndex)
            run.font.name = self.unicodeFont

        self.processSentences(p)

        if self.collectConvertedWordFrequency:
            self.updateWordsFrequencies(p)
        return
    
    def processSentences(self, p):
        # Deal with questions and exclamations, inserting
        # initial marks at the start of sentences.
        
        # Get all the positions of sentence endings
        sentence_ends, sentence_starts = \
            self.computeSentenceStartsEnds(p.text)
        run_map = self.mapRunsToParagraphTextPosisions(p.runs)

        startRuns = []
        rIndex = 0
        for sIndex in range(0, len(sentence_starts)):
            startPos = sentence_starts[sIndex]
            if rIndex >= len(run_map):
                x = 10
            while rIndex < len(run_map) and run_map[rIndex][1] < startPos:
                rIndex += 1
                if rIndex >= len(run_map):
                    break
            startRuns.append(rIndex)

        # Patch for capitals and punctuation at sentence starts.
        for sIndex in range(0, len(startRuns)):
            runId = startRuns[sIndex]
            if runId >= len(run_map):
                break
            run = run_map[runId][2]
            # This is the run.
            text = run.text
            offset = sentence_starts[sIndex] - run_map[runId][0]  # Where the text actually starts
            capped = text[offset:].capitalize()  # Capitalized portion
            firstPart = text[0:offset] # Before the capitalized section
            # Check for end character to prepend
            charEnd = sentence_ends[sIndex][1]
            if charEnd in self.pre_punctuation:
               newStart = self.pre_punctuation[charEnd]
            else:
                newStart = ''
            # Put text back in run
            try:
                run.text = firstPart + newStart + capped
            except:
                run.text = '*BROKEN* *Broken*'
        return

  # Given a start position in the paragraph text, return run and place there.
    def textPositionInRun(self, run_map, start):
        # TODO: Ignore some characters at start, e.g., digits, space, punctuation
        for map in run_map:
             if start >= map[0] and start <= map[1]:
                return (map[2], start - map[0])
        return (None, None)

    # Frequency processing for a paragraph's text
    def updateWordsFrequencies(self, para):
        pText = para.text
        words = self.wordSplitRegEx.split(pText)
        for word in words:
            # Should ignore empty non-word items
            if word and word != ' ':
                self.addWordToFrequencyList(word)


# TODO: Test more Adlam text!
def testConvert():
  # Debug!
  testcases = {
    'latn': {
        'fontIndex': 3,  # For latin
        'toLower': False,
        'sentenceCase': False,
        'tests': [
          # ['KAALDEN GOONGA : â€œMaa laaÉ“, Ã±amlel ko joÉ“el!',
          #  "ğ¥ ğ¤‘ğ¤€ğ¥„ğ¤‚ğ¤ğ¤‰ğ¤ ğ¤˜ğ¤Œğ¥…ğ¤'ğ¤˜ğ¤€ : â€œğ¤ƒğ¤¢ğ¥„ ğ¤¤ğ¤¢ğ¥„ğ¤©â¹ ğ¤»ğ¤¢ğ¤¥ğ¤¤ğ¤«ğ¤¤ ğ¤³ğ¤® ğ¤¶ğ¤®ğ¤©ğ¤«ğ¤¤!"
          #  ],
            ['Tyaldhi welen', 'ğ¤•ğ¤¢ğ¤¤ğ¤¯ğ¤­ ğ¤±ğ¤«ğ¤¤ğ¤«ğ¤²' ],  # line 220
            ['Dyowi', 'ğ¤”ğ¤®ğ¤±ğ¤­'],  # line 331
        ],
    },
    'arab': {
        'fontIndex': 0,
        'toLower': True,
        'sentenceCase': True,
        'tests': [
            ['Ø¨Ø«Ø¨!', 'ğ¥ğ¤€ğ¤¤ğ¤¢!'],
            ['Ø¨Ø«Ø¨?', 'ğ¥Ÿğ¤€ğ¤¤ğ¤¢?'],
            ["Ù‚Ø¸ÙƒØªØ¶ÙƒØªØ¶Ùƒ ÙŠØ¨ÙƒÚ„Ø¶Ùƒ Ø¶ Ù¾â€Ø¨Ø«â€â€ŒØ¨ Ø³Ù†Ø«â€Ø¨Øµ",
             'ğ¤ğ¤­ğ¤²ğ¤£ğ¤«ğ¤²ğ¤£ğ¤«ğ¤² ğ¤¶ğ¤¢ğ¤²ğ¤ºğ¤«ğ¤² ğ¤« ğ¤¸ğ¤¢ğ¤¤ğ¤¢ ğ¤¨ğ¤µğ¤¤ğ¤¢ğ¤ª'
            ],
            [ 'Ù„Ù†Ø¬Ø³Ø¸Ú‡Ø¨Ø« Ù„Ù†Ø¬Ø³Ø¸Ú‡Ø¨Ø« Ø¨Ø«Ø¨ Ù¾Ø¶Ø®Ø«Ø¨Ø« Ù‚Ø¨ØºØ¨ÃƒÙƒÃ«Ú„Ø¨Ø« Ú¯Ø¨ØµÙ„Ø¸!',
             'ğ¥ğ¤‘ğ¤µğ¤¥ğ¤¨ğ¤­ğ¤¼ğ¤¢ğ¤¤ ğ¤³ğ¤µğ¤¥ğ¤¨ğ¤­ğ¤¼ğ¤¢ğ¤¤ ğ¤¢ğ¤¤ğ¤¢ ğ¤¸ğ¤«ğ¤§ğ¤¤ğ¤¢ğ¤¤ ğ¤±ğ¤¢ğ¤¯ğ¤¢â€¢ğ¤²â€¢ğ¤ºğ¤¢ğ¤¤ ğ¤¦ğ¤¢ğ¤ªğ¤³ğ¤­!'
            ],
            ['Ù„Ù†Ø¬Ø³Ø¸Ú‡Ø¨Ø« Ù„Ù†Ø¬Ø³Ø¸Ú‡Ø¨Ø« Ø¨Ø«Ø¨ Ù¾Ø¶Ø®Ø«Ø¨Ø« Ù‚Ø¨ØºØ¨ÃƒÙƒÃ«Ú„Ø¨Ø« Ú¯Ø¨ØµÙ„?',
             'ğ¥Ÿğ¤‘ğ¤µğ¤¥ğ¤¨ğ¤­ğ¤¼ğ¤¢ğ¤¤ ğ¤³ğ¤µğ¤¥ğ¤¨ğ¤­ğ¤¼ğ¤¢ğ¤¤ ğ¤¢ğ¤¤ğ¤¢ ğ¤¸ğ¤«ğ¤§ğ¤¤ğ¤¢ğ¤¤ ğ¤±ğ¤¢ğ¤¯ğ¤¢â€¢ğ¤²â€¢ğ¤ºğ¤¢ğ¤¤ ğ¤¦ğ¤¢ğ¤ªğ¤³?'
             ]
        ]
    },
  }

  adlamConverter = AdlamConverter(FONTS_TO_CONVERT, thisDefaultOutputFont)
  for script in testcases:
    fontIndex = testcases[script]['fontIndex']
    toLower = testcases[script]['toLower']
    sentenceCase = testcases[script]['sentenceCase']
    # Set lower and sentence modes
    adlamConverter.setLowerMode(toLower)
    adlamConverter.setSentenceMode(sentenceCase)
    for test in testcases[script]['tests']:
      input = test[0]
      expected = test[1]

      result = adlamConverter.convertText(input,
                                          fontIndex=fontIndex)
      if result != expected:
        print ('** Unexpected results: \n  expected(%d) = %s\n  Result(%d)   = %s' % (
          len(expected), expected, len(result), result))
        print('Old text = %s' % input)
      else:
        print ('* PASSES * %s case %s  ' % (script, expected))

def testParagraph():
    # Checks how paragraph operations work, e.g., split, inserting punctuation
    # at front.
    test_paragraphs = [
        'Ù£)- ÙØ¶ÙÙ‚Ù† ØºØ¸Ù ØºØ¹Ø¹ Ù„Ø¹ÙƒÚ„Ø¸: Ø«Ø¨ØµØ¨Ø«â¹ Ø«Ø¨ØµØ¶â¹ Ù¾Ø¶Ø«ÙŒØ¹â¹ Ù„Ø¶Ø«ÙŒØ¶â¹ Ù»Ø¨ÙÙƒÚ„Ø¹Ø«â¹ Ù»Ø¨ÙØ«Ø¸â¹ Ø«Ø¶Ú„ÙŒØ¨Ø«â¹ Ø«Ø¶Ú„ØºØ¶â¹ Ø«Ø¶Ù„ÙŒØ¸Ù¾Ø¸â¹ Ø«Ø¶Ù„ØºØ¶â¹ Ø«Ø¶Ù„ÙŒØ¸â¹ Ø«Ø¶Ù„ÙŒØ¶ÙØ«Ø¶â¹ ØªØ¶Ù‚Ú„Ø¨Ø«â¹ ØªØ¶Ù‚Ø«Ø¶â¹ Ø¶ Ù„Ø¹ Ø·Ù€Ø¨Ú‡Ø¸ØºÙ Ø¶ ØºØ¸Ù Ù„Ø¹ÙƒÚ„Ø¸ ØªØ¹Ù‚ ØºØ¹Ø¹ØŸ',
        'Ù£)- ÙØ¶ÙÙ‚Ù† ØºØ¸Ù ØºØ¹Ø¹ Ù„Ø¹ÙƒÚ„Ø¸: Ø«Ø¨ØµØ¨Ø«â¹ Ø«Ø¨ØµØ¶â¹ Ù¾Ø¶Ø«ÙŒØ¹â¹ Ù„Ø¶Ø«ÙŒØ¶â¹ Ù»Ø¨ÙÙƒÚ„Ø¹Ø«â¹ Ù»Ø¨ÙØ«Ø¸â¹ Ø«Ø¶Ú„ÙŒØ¨Ø«â¹ Ø«Ø¶Ú„ØºØ¶â¹ Ø«Ø¶Ù„ÙŒØ¸Ù¾Ø¸â¹ Ø«Ø¶Ù„ØºØ¶â¹ Ø«Ø¶Ù„ÙŒØ¸â¹ Ø«Ø¶Ù„ÙŒØ¶ÙØ«Ø¶â¹ ØªØ¶Ù‚Ú„Ø¨Ø«â¹ ØªØ¶Ù‚Ø«Ø¶â¹ Ø¶ Ù„Ø¹ Ø·Ù€Ø¨Ú‡Ø¸ØºÙ Ø¶ ØºØ¸Ù Ù„Ø¹ÙƒÚ„Ø¸ ØªØ¹Ù‚ ØºØ¹Ø¹!',
        '  ?Ø¶ Ø¬Ø¸Ø®Ø¨Ø«: Ù„Ø¨Øµ Ø¶ Ø¬Ø¸Ø®Ø¨Ø«: Ù„Ø¨Øµ .Ø¶ Ø¬Ø¸Ø®Ø¨Ø«: Ù„Ø¨Øµ!'

    ]
    adlamConverter = AdlamConverter(FONTS_TO_CONVERT, thisDefaultOutputFont)
    for test in test_paragraphs:
        result = adlamConverter.findSentencesInParagraph(test)


def convertDocx(files):
    adlamConverter = adlamConversion.AdlamConverter()      

    try:
        adlamConverter.setScriptIndex(scriptIndex)
        adlamConverter.setLowerMode(True)
        adlamConverter.setSentenceMode(True)
        paragraphs = doc.paragraphs
        count = len(paragraphs)
        msgToSend = '%d paragraphs in %s\n' % (count, fileName)
        countSent = 0

    except BaseException as err:
        return 'Bad Adlam converter. Err = %s' % err
        
    if app.debug:
        print('Created converter')

    try:
        docConverter = ConvertDocx(adlamConverter, documentIn=doc,
                                       reportProgressFn=progressFn)

        if docConverter:
            result = docConverter.processDocx()
    except BaseException as err:
        return 'Error in docConverter. Err = %s' % err


def testPunctuation():
    t = ["\u0601", "\0u60c", "\u060b", ]

    converter = AdlamConverter()

    for text in t:
        r = converter.convertText(text, fontIndex=0)
        print("%s --> %s" % (text, r))
    
def keyLen(x):
    return len(x)

def makeLatnRegex():
    latnMap = conv.private_use_map['latn']
    keyRegEx = latnMap.keys()
    keyRegEx.sort(reverse=True, key=keyLen)
    print(keyRegEx)
    return '|'.join(keyRegEx)

def convertAdlamToLatin(converter, text):
    return

def roundTripALA(converter):
    # Get Latin text
    
    adlam = converter.convertText(latin2, fontIndex=LATIN2ADLAM)
    # get Adlam text
    latin2 = converter.convertText(adlam, fontIndex=LATIN2ADLAM)
    # convert to Latin
    adlam = converter.convertText(latin2, fontIndex=ADLAT2LATIN)
    # convert back to Adlam2
    # convert to Latin2
    # compare them
    return


def main(argv):
    converter = AdlamConverter()
    #convertDocFiles(argv[2:])
    # testPunctuation()
    testConvert()
    #testParagraph()


if __name__ == '__main__':
  main(sys.argv)
